{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d408af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(\"../LMSCNet\")\n",
    "from LMSCNet.common.seed import seed_all\n",
    "from LMSCNet.common.config import CFG\n",
    "from LMSCNet.common.dataset import get_dataset\n",
    "from LMSCNet.common.model import get_model\n",
    "from LMSCNet.common.logger import get_logger\n",
    "from LMSCNet.common.optimizer import build_optimizer, build_scheduler\n",
    "from LMSCNet.common.io_tools import dict_to\n",
    "from LMSCNet.common.metrics import Metrics\n",
    "import LMSCNet.common.checkpoint as checkpoint\n",
    "\n",
    "from Data.dataset import CarlaDataset, collate_fn_test\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.models as models\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "import open3d as o3d\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pdb\n",
    "from PIL import Image\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc0c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMSCNet(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Encoder_block1): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (Encoder_block2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (Encoder_block3): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (Encoder_block4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (conv_out_scale_1_8): Conv2d(320, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (seg_head_1_8): SegmentationHead(\n",
      "    (conv0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv1): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn1): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn2): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv_classes): Conv3d(8, 23, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (deconv_1_8__1_2): ConvTranspose2d(16, 16, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (deconv_1_8__1_1): ConvTranspose2d(16, 16, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (deconv1_8): ConvTranspose2d(16, 16, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (conv1_4): Conv2d(272, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_out_scale_1_4): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (seg_head_1_4): SegmentationHead(\n",
      "    (conv0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv1): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn1): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn2): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv_classes): Conv3d(8, 23, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (deconv_1_4__1_1): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (deconv1_4): ConvTranspose2d(32, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (conv1_2): Conv2d(240, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_out_scale_1_2): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (seg_head_1_2): SegmentationHead(\n",
      "    (conv0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv1): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn1): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn2): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv_classes): Conv3d(8, 23, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      "  (deconv1_2): ConvTranspose2d(64, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "  (conv1_1): Conv2d(240, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (seg_head_1_1): SegmentationHead(\n",
      "    (conv0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv1): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn1): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2): ModuleList(\n",
      "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "      (2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3), bias=False)\n",
      "    )\n",
      "    (bn2): ModuleList(\n",
      "      (0): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv_classes): Conv3d(8, 23, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dtype = torch.float32  # Tensor type to be used\n",
    "\n",
    "from LMSCNet.models.LMSCNet import LMSCNet\n",
    "\n",
    "# Calculated acoording to train dataset\n",
    "class_frequencies = np.array([\n",
    "    0.00,\n",
    "    6.29,\n",
    "    1.86,\n",
    "    0.03,\n",
    "    0.16,\n",
    "    0.67,\n",
    "    0.78,\n",
    "    50.25,\n",
    "    17.21,\n",
    "    2.63,\n",
    "    5.89,\n",
    "    4.46,\n",
    "    0.03,\n",
    "    0.00,\n",
    "    1.14,\n",
    "    0.17,\n",
    "    0.00,\n",
    "    3.07,\n",
    "    0.01,\n",
    "    0.71,\n",
    "    0.27,\n",
    "    0.01,\n",
    "    4.35,\n",
    "])\n",
    "\n",
    "model = LMSCNet(class_num=23, input_dimensions=[128, 128, 8], class_frequencies=class_frequencies)\n",
    "\n",
    "optimizer = optim.Adam(model.get_parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# Moving optimizer and model to used device\n",
    "model = model.to(device=device)\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9715f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Data/Scenes/Cartesian/Train\"\n",
    "\n",
    "coordinate_type = \"cartesian\"\n",
    "cylindrical = coordinate_type==\"cylindrical\"\n",
    "T = 1\n",
    "B = 4 # Matching paper\n",
    "\n",
    "carla_ds = CarlaDataset(directory=data_dir, device=device, num_frames=T, cylindrical=cylindrical)\n",
    "dataloader = DataLoader(carla_ds, batch_size=B, shuffle=True, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c0661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLORS = np.array([\n",
    "    (255, 255, 255), # None\n",
    "    (70, 70, 70),    # Building\n",
    "    (100, 40, 40),   # Fences\n",
    "    (55, 90, 80),    # Other\n",
    "    (255, 255, 0),   # Pedestrian\n",
    "    (153, 153, 153), # Pole\n",
    "    (157, 234, 50),  # RoadLines\n",
    "    (0, 0, 255),  # Road\n",
    "    (255, 255, 255),  # Sidewalk\n",
    "    (0, 155, 0),  # Vegetation\n",
    "    (255, 0, 0),     # Vehicle\n",
    "    (102, 102, 156), # Wall\n",
    "    (220, 220, 0),   # TrafficSign\n",
    "    (70, 130, 180),  # Sky\n",
    "    (255, 255, 255),     # Ground\n",
    "    (150, 100, 100), # Bridge\n",
    "    (230, 150, 140), # RailTrack\n",
    "    (180, 165, 180), # GuardRail\n",
    "    (250, 170, 30),  # TrafficLight\n",
    "    (110, 190, 160), # Static\n",
    "    (170, 120, 50),  # Dynamic\n",
    "    (45, 60, 150),   # Water\n",
    "    (145, 170, 100), # Terrain\n",
    "]) / 255.0 # normalize each channel [0-1] since is what Open3D uses\n",
    "\n",
    "def visualize_preds(probs, min_dim, max_dim, num_samples, cylindrical=True, min_thresh=0.75):\n",
    "    preds = np.argmax(probs, axis=3)\n",
    "    max_probs = np.amax(probs, axis=3)\n",
    "    intervals = (max_dim - min_dim) / preds.shape\n",
    "    \n",
    "    \n",
    "    x = np.linspace(min_dim[0], max_dim[0], num=preds.shape[0]) + intervals[0] / 2\n",
    "    y = np.linspace(min_dim[1], max_dim[1], num=preds.shape[1]) + intervals[1] / 2\n",
    "    z = np.linspace(min_dim[2], max_dim[2], num=preds.shape[2]) + intervals[2] / 2\n",
    "    xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "    valid_cells = max_probs > min_thresh \n",
    "    valid_x = xv[valid_cells]\n",
    "    valid_y = yv[valid_cells]\n",
    "    valid_z = zv[valid_cells]\n",
    "    labels = preds[valid_cells]\n",
    "\n",
    "    valid_points = np.stack((valid_x, valid_y, valid_z)).T\n",
    "    non_free = labels != 0\n",
    "    valid_points = valid_points[non_free, :]\n",
    "    labels = labels[non_free]\n",
    "\n",
    "    # Fill in voxels\n",
    "    N, __ = valid_points.shape\n",
    "    new_points = np.random.uniform((valid_points - intervals / 2).reshape(N, 3, 1),\n",
    "                                   (valid_points + intervals / 2).reshape(N, 3, 1),\n",
    "                                   (N, 3, num_samples))\n",
    "    new_labels = np.zeros((N, num_samples), dtype=np.uint32)\n",
    "    labels = (new_labels + labels.reshape(-1, 1)).reshape(-1)\n",
    "    valid_points = np.transpose(new_points, (0, 2, 1)).reshape(-1, 3)\n",
    "\n",
    "    if cylindrical:\n",
    "        x = (valid_points[:, 0] * np.cos(valid_points[:, 1])).reshape(-1, 1)\n",
    "        y = (valid_points[:, 0] * np.sin(valid_points[:, 1])).reshape(-1, 1)\n",
    "        points = np.hstack((x, y, valid_points[:, 2:]))\n",
    "    else:\n",
    "        points = valid_points\n",
    "\n",
    "    # swap axes\n",
    "    new_points = np.zeros(points.shape)\n",
    "    new_points[:, 0] = points[:, 2]\n",
    "    new_points[:, 1] = points[:, 0]\n",
    "    new_points[:, 2] = points[:, 1]\n",
    "    points = new_points\n",
    "\n",
    "    print(points.shape, labels.shape)\n",
    "\n",
    "    int_color = LABEL_COLORS[labels]\n",
    "    point_list = o3d.geometry.PointCloud()\n",
    "    point_list.points = o3d.utility.Vector3dVector(points)\n",
    "    point_list.colors = o3d.utility.Vector3dVector(int_color)\n",
    "    \n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(\n",
    "    window_name='Segmented Scene',\n",
    "    width=960,\n",
    "    height=540,\n",
    "    left=480,\n",
    "    top=270)\n",
    "    vis.get_render_option().background_color = [0.0, 0.0, 0.0]\n",
    "    vis.get_render_option().point_size = 5\n",
    "    vis.get_render_option().show_coordinate_frame = True\n",
    "    \n",
    "    geometry = o3d.geometry.PointCloud(point_list)\n",
    "    vis.add_geometry(geometry)\n",
    "    \n",
    "    for i in range(500):\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        time.sleep(0.005)\n",
    "\n",
    "    return point_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e04b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tensorboard logging\n",
    "writer = SummaryWriter('runs/lmscnet/'+coordinate_type)\n",
    "\n",
    "# def update_board():\n",
    "#     writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "\n",
    "def plot_training_loss(running_loss, epoch, dataloader, count):\n",
    "    # ...log the running loss\n",
    "    print(\"logging training loss...\")\n",
    "    writer.add_scalar('training loss',\n",
    "                    running_loss / 1000,\n",
    "                    epoch * len(dataloader) + count)\n",
    "\n",
    "    # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "    # random mini-batch\n",
    "    # writer.add_figure('predictions vs. actuals',\n",
    "    #                 plot_classes_preds(net, inputs, labels),\n",
    "    #                 global_step=epoch * len(dataloader) + count)\n",
    "    running_loss = 0.0\n",
    "\n",
    "def plot_miou(pred, ground_truth, epoch, dataloader, count):\n",
    "    print(\"logging IoU score...\")\n",
    "\n",
    "    # Compute number of matches for each label\n",
    "    # labels, gt_counts = torch.unique(ground_truth, return_counts=True, dim=1, sorted=True)\n",
    "    jaccard = JaccardIndex(num_classes=23)\n",
    "    iou_score = jaccard(pred.cpu(), ground_truth.cpu())\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('IoU Score',\n",
    "                    iou_score,\n",
    "                    epoch * len(dataloader) + count)\n",
    "\n",
    "def save_model(model, model_name, model_dir):\n",
    "    '''\n",
    "    Saves trained pytorch model\n",
    "    '''\n",
    "    save_dir = os.path.join(model_dir, model_name)\n",
    "    torch.save(model.state_dict(), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03787ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dim = torch.tensor(carla_ds._eval_param['min_bound'], device=device) \n",
    "max_dim = torch.tensor(carla_ds._eval_param['max_bound'], device=device)\n",
    "\n",
    "def gen_voxel_grid(x_in, grid_dims, B, T):\n",
    "    voxel_grid = torch.zeros(B, T, grid_dims[0], grid_dims[1], grid_dims[2], device=device)\n",
    "    intervals = (max_dim - min_dim) / grid_dims\n",
    "\n",
    "    for b_i in range(B):\n",
    "        for t_i in range(T):\n",
    "            points = x_in[b_i][t_i][:, :3]\n",
    "            # No points for this frame\n",
    "            if points.shape[0] == 1:\n",
    "                continue\n",
    "            # Valid voxels (make sure to clip)\n",
    "            valid_point_mask = torch.all((points < max_dim.view(1, 3)) &\n",
    "                                            (points >= min_dim.view(1, 3)), 1)\n",
    "            valid_points = points[valid_point_mask, :]\n",
    "            voxels = torch.floor((valid_points - min_dim) / intervals)\n",
    "            # Clamp to account for any floating point errors\n",
    "            voxels = torch.clamp(voxels, torch.zeros(3, device=device).view(1, 3),\n",
    "                                    torch.tensor(grid_dims, device=device).view(1, 3) - 1)\n",
    "            print(torch.max(voxels, dim=0))\n",
    "            # This line is needed to create a mask with number of points, not just binary occupied\n",
    "            unique_voxels, counts = torch.unique(voxels, return_counts=True, dim=0)\n",
    "            voxel_grid[b_i, t_i, unique_voxels[:, 0].long(), unique_voxels[:, 1].long(), unique_voxels[:, 2].long()] += counts\n",
    "\n",
    "    return voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60fba728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([127., 100.,   7.], device='cuda:0'),\n",
      "indices=tensor([1227, 6368,    0], device='cuda:0'))\n",
      "torch.return_types.max(\n",
      "values=tensor([127.,  88.,   7.], device='cuda:0'),\n",
      "indices=tensor([  117, 19125,     4], device='cuda:0'))\n",
      "torch.return_types.max(\n",
      "values=tensor([127., 127.,   7.], device='cuda:0'),\n",
      "indices=tensor([   8, 3075,    0], device='cuda:0'))\n",
      "torch.return_types.max(\n",
      "values=tensor([127., 124.,   7.], device='cuda:0'),\n",
      "indices=tensor([ 719, 1042,    0], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tigeriv/.local/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5976/2696979121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpreds_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lmscnet_ssc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lmscnet_ssc/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lmscnet_ssc/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "class_weights = model.get_class_weights().to(\"cuda\").type(torch.float32)\n",
    "grid_dims = torch.tensor(carla_ds._grid_size, dtype=torch.int64, device=device)\n",
    "\n",
    "running_loss = 0.0\n",
    "output_masked = None\n",
    "preds_masked = None\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "for epoch in range(epoch_num):\n",
    "    running_loss = 0.0\n",
    "    counter = 0\n",
    "    for input_data, output, counts in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        # counts = torch.unsqueeze(counts, 1)\n",
    "\n",
    "        counts = gen_voxel_grid(input_data, grid_dims, B, T)\n",
    "\n",
    "        # counts = counts.permute(0, 1, 2, 4, 3)\n",
    "        x = {\"3D_OCCUPANCY\": counts}\n",
    "        preds = model(x)[\"pred_semantic_1_1\"]\n",
    "        preds = torch.permute(preds, (0, 2, 3, 4, 1))\n",
    "        output = output.permute(0, 1, 3, 2)     \n",
    "        \n",
    "        if counter % 1000 == 99:\n",
    "            probs = nn.functional.softmax(preds, dim = 4)\n",
    "            # visualize_preds(probs[0].detach().cpu().numpy(), np.asarray(carla_ds._eval_param[‘min_bound’]),\n",
    "            #                 np.asarray(carla_ds._eval_param[‘max_bound’]), 10, cylindrical=cylindrical)        counts = counts.contiguous().view(-1)\n",
    "        \n",
    "        counts = counts.contiguous().view(-1)\n",
    "        output = output.contiguous().view(-1).long()\n",
    "        preds = preds.contiguous().view(-1, preds.shape[4])        \n",
    "\n",
    "        # Criterion requires input (NxC), output (N) dimension\n",
    "        mask = counts > 0\n",
    "        output_masked = output[mask]\n",
    "        preds_masked = preds[mask]\n",
    "        loss = criterion(preds_masked, output_masked)\n",
    "        # print(loss)        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if counter%1000==99:\n",
    "            plot_miou(preds_masked, output_masked, epoch, dataloader, counter)\n",
    "            plot_training_loss(running_loss, epoch, dataloader, counter)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        counter += 1\n",
    "    # Save model weights at the end of each epoch\n",
    "    model_weights_name = \"model_weights_epoch{epochnum:n}\".format(epochnum=epoch)\n",
    "    model_save_dir = \"runs/lmscnet/{ctype:<}/model_weights\".format(ctype = coordinate_type)\n",
    "    save_model(model, model_weights_name, model_save_dir)\n",
    "    \n",
    "    print(f'Epoch Num: {epoch} ------ loss: {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model_weights_name = \"model_weights\"\n",
    "model_save_dir = \"runs/lmscnet/{ctype:<}/model_weights\".format(ctype = coordinate_type)\n",
    "save_model(model, model_weights_name, model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195880, 3) (195880,)\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: GLX: Failed to create context: GLXBadFBConfig\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'background_color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4898/1004666230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m visualize_preds(probs[5].detach().cpu().numpy(), np.asarray(carla_ds._eval_param['min_bound']), \n\u001b[0;32m----> 2\u001b[0;31m                             np.asarray(carla_ds._eval_param['max_bound']), 10, cylindrical=cylindrical)\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4898/2917458102.py\u001b[0m in \u001b[0;36mvisualize_preds\u001b[0;34m(probs, min_dim, max_dim, num_samples, cylindrical, min_thresh)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     top=270)\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_render_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_render_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_render_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_coordinate_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'background_color'"
     ]
    }
   ],
   "source": [
    "visualize_preds(probs[5].detach().cpu().numpy(), np.asarray(carla_ds._eval_param['min_bound']), \n",
    "                            np.asarray(carla_ds._eval_param['max_bound']), 10, cylindrical=cylindrical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485b0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "006860318c21cac5072e2525a3c829cdadd8603ef251c1078a98f181e8c11327"
  },
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
