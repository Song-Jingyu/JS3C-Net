{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from utils import config\n",
    "# cfg = get_parser()\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import importlib\n",
    "import logging\n",
    "import shutil\n",
    "import spconv\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from utils.evaluate_completion import get_eval_mask\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import models.model_utils as model_utils\n",
    "from utils.np_ioueval import iouEval\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "args = config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticKITTI\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dtype = torch.float32  # Tensor type to be used\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args['gpu']\n",
    "\n",
    "\n",
    "\n",
    "LEARNING_RATE_CLIP = 1e-6\n",
    "MOMENTUM_ORIGINAL = 0.5\n",
    "MOMENTUM_DECCAY = 0.5\n",
    "BN_MOMENTUM_MAX = 0.001\n",
    "NUM_CLASS_SEG = args['DATA']['classes_seg']\n",
    "NUM_CLASS_COMPLET = args['DATA']['classes_completion']\n",
    "\n",
    "exp_name = args['log_dir']\n",
    "\n",
    "seg_head = importlib.import_module('models.'+args['Segmentation']['model_name'])\n",
    "seg_model = seg_head.get_model\n",
    "\n",
    "complet_head = importlib.import_module('models.'+args['Completion']['model_name'])\n",
    "complet_model = complet_head.get_model\n",
    "\n",
    "print(args['DATA']['dataset'])\n",
    "if args['DATA']['dataset'] == 'SemanticKITTI':\n",
    "    dataset = importlib.import_module('kitti_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/neofelis/Jingyu-SSD/carla_dataset/Train'\n",
    "\n",
    "coordinate_type = \"cartesian\"\n",
    "cylindrical = coordinate_type==\"cylindrical\"\n",
    "T = 1 #single sweep\n",
    "B = 4 # Matching paper\n",
    "\n",
    "from dataset import CarlaDataset\n",
    "\n",
    "carla_ds = CarlaDataset(directory=data_dir, device=device, num_frames=T, cylindrical=cylindrical, config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class J3SC_Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.seg_head = seg_model(args)\n",
    "        self.complet_head = complet_model(args)\n",
    "        self.voxelpool = model_utils.VoxelPooling(args)\n",
    "        self.seg_sigma = nn.Parameter(torch.Tensor(1).uniform_(0.2, 1), requires_grad=True)\n",
    "        self.complet_sigma = nn.Parameter(torch.Tensor(1).uniform_(0.2, 1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seg_inputs, complet_inputs, _ = x\n",
    "\n",
    "        '''Segmentation Head'''\n",
    "        seg_output, feat = self.seg_head(seg_inputs)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        '''Completion Head'''\n",
    "        coords = complet_inputs['complet_coords']\n",
    "        coords = coords[:, [0, 3, 2, 1]]\n",
    "\n",
    "        # if args['DATA']['dataset'] == 'SemanticKITTI':\n",
    "        #     coords[:, 3] += 1  # TODO SemanticKITTI will generate [256,256,31]\n",
    "        # elif args['DATA']['dataset'] == 'SemanticPOSS':\n",
    "        #     coords[:, 3][coords[:, 3] > 31] = 31\n",
    "\n",
    "        if args['Completion']['feeding'] == 'both':\n",
    "            feeding = torch.cat([seg_output, feat],1)\n",
    "        elif args['Completion']['feeding'] == 'feat':\n",
    "            feeding = feat\n",
    "        else:\n",
    "            feeding = seg_output\n",
    "        features = self.voxelpool(invoxel_xyz=complet_inputs['complet_invoxel_features'][:, :, :-1],\n",
    "                                    invoxel_map=complet_inputs['complet_invoxel_features'][:, :, -1].long(),\n",
    "                                    src_feat=feeding,\n",
    "                                    voxel_center=complet_inputs['voxel_centers'])\n",
    "        if self.args['Completion']['no_fuse_feat']:\n",
    "            features[...] = 1\n",
    "            features = features.detach()\n",
    "\n",
    "        batch_complet = spconv.SparseConvTensor(features.float(), coords.int(), args['Completion']['full_scale'], args['TRAIN']['batch_size'])\n",
    "        batch_complet = dataset.sparse_tensor_augmentation(batch_complet, complet_inputs['state'])\n",
    "\n",
    "        if args['GENERAL']['debug']:\n",
    "            model_utils.check_occupation(complet_inputs['complet_input'], batch_complet.dense())\n",
    "\n",
    "        complet_output = self.complet_head(batch_complet)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return seg_output, complet_output, [self.seg_sigma, self.complet_sigma]\n",
    "\n",
    "def bn_momentum_adjust(m, momentum):\n",
    "    if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
    "        m.momentum = momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     26\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# seg_label = batch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cylinder/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cylinder/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/cylinder/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jingyu/JS3C-Net/models/SubSparseConv.py:93\u001b[0m, in \u001b[0;36mMerge\u001b[0;34m(tbl)\u001b[0m\n\u001b[1;32m     90\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m seg_coord\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     91\u001b[0m     complet_invoxel_features\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mTensor(complet_invoxel_feature))\n\u001b[0;32m---> 93\u001b[0m seg_inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_coords\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     94\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_labels\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(seg_labels, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     95\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_features\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(seg_features, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     96\u001b[0m               }\n\u001b[1;32m     98\u001b[0m complet_inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplet_coords\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(complet_coords, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     99\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplet_input\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(input_vx, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    100\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoxel_centers\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(voxel_centers, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplet_invoxel_features\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mcat(complet_invoxel_features, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    105\u001b[0m                   }\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seg_inputs, complet_inputs, filenames\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = J3SC_Net(args).cuda()\n",
    "criteria = model_utils.Loss(args).cuda()\n",
    "\n",
    "train_dataloader = DataLoader(carla_ds, batch_size=B, shuffle=True, collate_fn=seg_head.Merge)\n",
    "training_epochs = args['TRAIN']['epochs']\n",
    "# training_epoch = model_utils.checkpoint_restore(classifier, experiment_dir, True, train_from=args['TRAIN']['train_from'])\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args['TRAIN']['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "global_epoch = 0\n",
    "best_iou_sem_complt = 0\n",
    "best_iou_complt = 0\n",
    "best_iou_seg = 0\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    classifier.train()\n",
    "    lr = max(args['TRAIN']['learning_rate'] * (args['TRAIN']['lr_decay'] ** (epoch // args['TRAIN']['decay_step'])), LEARNING_RATE_CLIP)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    momentum = max(MOMENTUM_ORIGINAL * (MOMENTUM_DECCAY ** (epoch // args['TRAIN']['decay_step'])), BN_MOMENTUM_MAX)\n",
    "    if momentum < 0.01:\n",
    "        momentum = 0.01\n",
    "    classifier = classifier.apply(lambda x: bn_momentum_adjust(x, momentum))\n",
    "    train_loss = 0\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            # seg_label = batch\n",
    "            print(len(batch[0]))\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06101282618436711328b81f67b356dccfc8ea185a33bf26c819a8f9eb824c27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cylinder': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
